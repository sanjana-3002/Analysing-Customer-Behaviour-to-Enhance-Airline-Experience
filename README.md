## Analysing-Customer-Behaviour-to-Enhance-Airline-Experience (ML+NLP)
From messy flight data to actionable CX: I used ML+NLP to predict satisfaction/loyalty on 129k rows (best RBF-SVM ~81.9% acc) and mine 64k reviews (TF-IDF) into detractor/passive/promoter themes. 

Story: reliability hurts; service lifts (Wi-Fi, boarding, crew, cleanliness) â†’ retention wins.

## ğŸš€ Overview:
- Purpose: Identify what drives satisfaction & loyalty and surface themes from reviews that teams can act on.
- How it works:
  (i) Tabular ML â†’ feature selection â†’ train & evaluate classifiers for Satisfaction and Loyalty.
  (ii) NLP â†’ clean reviews â†’ TF-IDF â†’ multi-class classification (Detractor/Passive/Promoter) + theme mining.
- Project modes
(i) Satisfaction (tabular)
(ii) Loyalty (tabular): Economy-only and Business-only subsets
(iii) Reviews (NLP): Multi-class classification + word themes

## âœ¨ Features:
- ML pipelines for satisfaction & loyalty with baseline models (LogReg/DT/RF/XGB/SVM)
- NLP pipeline (clean â†’ tokenize â†’ lemmatize â†’ TF-IDF â†’ classify)
- Interpretable outputs: feature importance (tree models), confusion matrices, class reports
- CX playbook mapping: reliability, boarding, Wi-Fi, crew/service, cleanliness

## ğŸ“Š Data & Results (notebooks)
- Tabular dataset: ~129,880 rows, ~24â€“26 columns
- Reviews dataset: 64,017 texts (NPS â†’ Detractor/Passive/Promoter)

Results (best per notebook)
- Satisfaction: accuracy â‰ˆ 0.807
- Loyalty â€“ Economy: accuracy â‰ˆ 0.920 (RandomForest, n_estimators=500)
- Loyalty â€“ Business: accuracy â‰ˆ 0.948 (RandomForest, n_estimators=100)
- Reviews (NLP): accuracy â‰ˆ 0.82 on test (TF-IDF baseline)

Signals often ranked high: Online boarding, Inflight Wi-Fi, Seat comfort, Inflight entertainment, Gate location, Departure/Arrival time convenience, Age (context), and overall Satisfaction when predicting Loyalty.

## ğŸ§± Architecture
[Raw Tabular] â”€â”    Clean/EDA â†’ Feature Selection â†’ Train (DT/RF/XGB/SVM) â†’ Metrics â†’ Insights
                â””â”€> 
[Reviews Text] â”€â”€> Clean â†’ Tokenize/Lemmatize â†’ TF-IDF â†’ Classify (NB/SVM) â†’ Themes â†’ Insights

## ğŸ“¦ Tech Stack

Python, pandas, scikit-learn, XGBoost, NLTK, wordcloud, Matplotlib/Seaborn, Jupyter

## ğŸ“ Repository Structure
.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ satisfaction.ipynb
â”‚   â”œâ”€â”€ Only Eco_Loyalty.ipynb
â”‚   â”œâ”€â”€ Only Business_Loyalty.ipynb
â”‚   â””â”€â”€ Text_Classification.ipynb
â”œâ”€â”€ data/            # (add your CSVs here; paths referenced in notebooks)
â”œâ”€â”€ figures/         # generated plots/wordclouds
â””â”€â”€ README.md

## âš™ï¸ Setup

Requirements: Python 3.10+, Jupyter

**Create & activate env**
python -m venv .venv
**Windows:**
.venv\Scripts\activate
**macOS/Linux:**
source .venv/bin/activate

**Install deps**
pip install -U pandas numpy scikit-learn xgboost nltk wordcloud matplotlib seaborn jupyter

**NLTK (one-time)**
python - <<'PY'
import nltk
for p in ["punkt","stopwords","wordnet","omw-1.4"]:
    nltk.download(p)
PY

## â–¶ï¸ Run

- Place your datasets in data/ (update paths in the first cell of each notebook if needed).

- Launch notebooks:

  - jupyter notebook notebooks/


Run cells top-to-bottom to reproduce metrics and figures.

## ğŸ§ª Tips & Testing

- Check class imbalance (e.g., Passive in NLP) â†’ try stratified splits, class weights, or resampling.

- Add precision/recall/F1, ROC-AUC, and probability calibration for production-grade evaluation.

- Compare Linear SVM vs Multinomial NB for TF-IDF; try BERT for a stronger baseline.

## ğŸ—ºï¸ Roadmap

- SHAP for model explanations

- Class rebalancing & threshold tuning

- Streamlit dashboard for CX readouts

- Upgrade NLP to transformer baselines (e.g., DistilBERT)

